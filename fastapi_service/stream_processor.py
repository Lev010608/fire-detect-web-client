# fastapi_service/stream_processor.py

import asyncio
import base64
import cv2
import json
import numpy as np
import os
import time
import threading
import uuid
from typing import Optional, Dict
from fastapi import WebSocketDisconnect


class VideoStreamProcessor:
    """
    ç”¨äºŽå¤„ç†WebSocketè§†é¢‘æµçš„ç±»
    å®žçŽ°é€å¸§å¤„ç†å’Œå®žæ—¶è¿”å›žç»“æžœ
    """

    def __init__(self, model, config, logger):
        self.model = model
        self.config = config
        self.logger = logger
        self.active_connections = {}  # å­˜å‚¨æ´»è·ƒçš„WebSocketè¿žæŽ¥
        self.processing_threads = {}  # å­˜å‚¨å¤„ç†çº¿ç¨‹
        self.stop_signals = {}  # å­˜å‚¨åœæ­¢ä¿¡å·

    async def register_connection(self, websocket, client_id: str):
        """æ³¨å†Œæ–°çš„WebSocketè¿žæŽ¥"""
        self.active_connections[client_id] = websocket
        self.stop_signals[client_id] = threading.Event()
        self.logger.info(f"Registered new connection: {client_id}")

        # å‘é€åˆå§‹ç¡®è®¤æ¶ˆæ¯
        await websocket.send_json({
            "type": "connection_established",
            "client_id": client_id,
            "message": "Connection established with video stream processor"
        })

    def unregister_connection(self, client_id: str):
        """æ³¨é”€WebSocketè¿žæŽ¥"""
        if client_id in self.active_connections:
            del self.active_connections[client_id]

        # è®¾ç½®åœæ­¢ä¿¡å·ï¼Œä¸­æ–­ä»»ä½•æ­£åœ¨è¿›è¡Œçš„å¤„ç†
        if client_id in self.stop_signals:
            self.stop_signals[client_id].set()
            del self.stop_signals[client_id]

        # æ¸…ç†ä»»ä½•æ´»è·ƒçš„çº¿ç¨‹
        if client_id in self.processing_threads:
            del self.processing_threads[client_id]

        self.logger.info(f"Unregistered connection: {client_id}")

    async def process_frame(self, frame_data, client_id: str, frame_id: Optional[int] = None):
        """å¤„ç†å•ä¸ªè§†é¢‘å¸§å¹¶è¿”å›žç»“æžœ"""
        try:
            # å°†base64ç¼–ç çš„å›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
            decoded_data = base64.b64decode(frame_data)
            np_arr = np.frombuffer(decoded_data, np.uint8)
            frame = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

            # è®°å½•å¸§å¤§å°
            self.logger.info(f"Processing frame {frame_id} for client {client_id}, shape: {frame.shape}")

            # è¿è¡Œæ¨¡åž‹æŽ¨ç†
            start_time = time.time()
            results = self.model(frame)[0]
            inference_time = time.time() - start_time

            # èŽ·å–æ£€æµ‹ç»“æžœ
            boxes = results.boxes
            detection_params = []

            if len(boxes) > 0:
                location_list = boxes.xyxy.cpu().numpy().tolist() if hasattr(boxes.xyxy, 'cpu') else boxes.xyxy.tolist()
                cls_list = boxes.cls.cpu().numpy().tolist() if hasattr(boxes.cls, 'cpu') else boxes.cls.tolist()
                conf_list = boxes.conf.cpu().numpy().tolist() if hasattr(boxes.conf, 'cpu') else boxes.conf.tolist()

                for box, cls, conf in zip(location_list, cls_list, conf_list):
                    cls_int = int(cls)
                    class_name = self.config.CH_names[cls_int] if cls_int < len(
                        self.config.CH_names) else f"æœªçŸ¥ç±»åˆ«{cls_int}"
                    detection_params.append({
                        "bbox": [int(x) for x in box],  # x1, y1, x2, y2
                        "class": cls_int,
                        "class_name": class_name,
                        "confidence": float(conf)
                    })

            # èŽ·å–æ ‡æ³¨åŽçš„å›¾åƒ
            annotated_frame = results.plot()

            # å°†å›¾åƒç¼–ç ä¸ºJPEGï¼Œç„¶åŽè½¬æ¢ä¸ºbase64
            _, buffer = cv2.imencode('.jpg', annotated_frame)
            encoded_frame = base64.b64encode(buffer).decode('utf-8')

            # æž„å»ºå¹¶è¿”å›žç»“æžœ
            result = {
                "type": "frame_result",
                "frame_id": frame_id,
                "detections": detection_params,
                "detection_count": len(detection_params),
                "annotated_frame": encoded_frame,
                "inference_time": round(inference_time * 1000, 2)  # æ¯«ç§’
            }

            # å‘é€ç»“æžœç»™å®¢æˆ·ç«¯
            if client_id in self.active_connections:
                await self.active_connections[client_id].send_json(result)
                return result

        except Exception as e:
            self.logger.error(f"Error processing frame {frame_id} for client {client_id}: {str(e)}")
            if client_id in self.active_connections:
                await self.active_connections[client_id].send_json({
                    "type": "error",
                    "frame_id": frame_id,
                    "message": str(e)
                })
            return None

    async def start_video_processing(self, video_path, client_id, save_output=False, output_path=None):
        """å¤„ç†è§†é¢‘æ–‡ä»¶ï¼Œé€å¸§å‘é€ç»“æžœ"""
        if client_id not in self.active_connections:
            self.logger.error(f"No active connection for client {client_id}")
            return

        websocket = self.active_connections[client_id]
        stop_signal = self.stop_signals.get(client_id)

        # ä½¿ç”¨çº¿ç¨‹å¤„ç†è§†é¢‘ï¼Œé¿å…é˜»å¡žWebSocket
        processing_thread = threading.Thread(
            target=self._process_video_in_thread,
            args=(video_path, client_id, websocket, stop_signal, save_output, output_path)
        )
        self.processing_threads[client_id] = processing_thread
        processing_thread.start()

        # å‘é€ç¡®è®¤æ¶ˆæ¯
        await websocket.send_json({
            "type": "processing_started",
            "client_id": client_id,
            "video_path": video_path,
            "save_output": save_output,
            "output_path": output_path
        })

    def _process_video_in_thread(self, video_path, client_id, websocket, stop_signal, save_output, output_path):
        """åœ¨çº¿ç¨‹ä¸­å¤„ç†è§†é¢‘"""
        try:
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                asyncio.run(self._send_error(websocket, f"Could not open video file: {video_path}"))
                return

            # èŽ·å–è§†é¢‘å±žæ€§
            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

            # è®¾ç½®è§†é¢‘å†™å…¥å™¨ï¼ˆå¦‚æžœéœ€è¦ä¿å­˜ï¼‰
            video_writer = None
            if save_output and output_path:
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                video_writer = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

            # å‘é€è§†é¢‘ä¿¡æ¯
            asyncio.run(websocket.send_json({
                "type": "video_info",
                "width": frame_width,
                "height": frame_height,
                "fps": fps,
                "total_frames": total_frames
            }))

            # ðŸ”¥ æ–°å¢žï¼šç»Ÿè®¡ä¿¡æ¯
            total_detections = 0
            all_frame_results = []  # å­˜å‚¨æ‰€æœ‰å¸§çš„æ£€æµ‹ç»“æžœ
            processing_start_time = time.time()

            # å¤„ç†æ¯ä¸€å¸§
            frame_id = 0
            while True:
                # æ£€æŸ¥æ˜¯å¦æœ‰åœæ­¢ä¿¡å·
                if stop_signal and stop_signal.is_set():
                    self.logger.info(f"Stopping video processing for client {client_id} due to stop signal")
                    break

                ret, frame = cap.read()
                if not ret:
                    break

                # è¿è¡Œæ¨¡åž‹æŽ¨ç†
                start_time = time.time()
                results = self.model(frame)[0]
                inference_time = time.time() - start_time

                # èŽ·å–æ£€æµ‹ç»“æžœ
                boxes = results.boxes
                detection_params = []

                if len(boxes) > 0:
                    location_list = boxes.xyxy.cpu().numpy().tolist() if hasattr(boxes.xyxy,
                                                                                 'cpu') else boxes.xyxy.tolist()
                    cls_list = boxes.cls.cpu().numpy().tolist() if hasattr(boxes.cls, 'cpu') else boxes.cls.tolist()
                    conf_list = boxes.conf.cpu().numpy().tolist() if hasattr(boxes.conf, 'cpu') else boxes.conf.tolist()

                    for box, cls, conf in zip(location_list, cls_list, conf_list):
                        cls_int = int(cls)
                        class_name = self.config.CH_names[cls_int] if cls_int < len(
                            self.config.CH_names) else f"æœªçŸ¥ç±»åˆ«{cls_int}"
                        detection_params.append({
                            "bbox": [int(x) for x in box],
                            "class": cls_int,
                            "class_name": class_name,
                            "confidence": float(conf)
                        })

                # ðŸ”¥ ç´¯è®¡æ£€æµ‹ç»Ÿè®¡
                total_detections += len(detection_params)
                all_frame_results.append(detection_params)

                # èŽ·å–æ ‡æ³¨åŽçš„å›¾åƒ
                annotated_frame = results.plot()

                # ä¿å­˜åˆ°è¾“å‡ºè§†é¢‘ï¼ˆå¦‚æžœéœ€è¦ï¼‰
                if video_writer:
                    video_writer.write(annotated_frame)

                # å°†å›¾åƒç¼–ç ä¸ºJPEGï¼Œç„¶åŽè½¬æ¢ä¸ºbase64
                _, buffer = cv2.imencode('.jpg', annotated_frame)
                encoded_frame = base64.b64encode(buffer).decode('utf-8')

                # æž„å»ºç»“æžœ
                result = {
                    "type": "frame_result",
                    "frame_id": frame_id,
                    "detections": detection_params,
                    "detection_count": len(detection_params),
                    "annotated_frame": encoded_frame,
                    "inference_time": round(inference_time * 1000, 2),  # æ¯«ç§’
                    "progress": {
                        "current": frame_id + 1,
                        "total": total_frames,
                        "percent": round((frame_id + 1) / total_frames * 100, 2)
                    }
                }

                # å‘é€ç»“æžœ
                asyncio.run(websocket.send_json(result))

                frame_id += 1

                # æŽ§åˆ¶å‘é€é€ŸçŽ‡ï¼Œé¿å…å®¢æˆ·ç«¯è¿‡è½½
                time.sleep(1 / fps)  # å°è¯•ä»¥åŽŸè§†é¢‘å¸§çŽ‡å‘é€

            # å®Œæˆå¤„ç†ï¼Œé‡Šæ”¾èµ„æº
            cap.release()
            if video_writer:
                video_writer.release()

            # ðŸ”¥ è®¡ç®—å¤„ç†ç»Ÿè®¡ä¿¡æ¯
            processing_end_time = time.time()
            total_processing_time = processing_end_time - processing_start_time

            # ðŸ”¥ å‘é€å®Œæˆæ¶ˆæ¯ - åŒ…å«å®Œæ•´ä¿¡æ¯
            complete_message = {
                "type": "processing_complete",
                "client_id": client_id,
                "video_info": {
                    "width": frame_width,
                    "height": frame_height,
                    "fps": fps,
                    "duration": total_frames / fps if fps > 0 else 0
                },
                "processing_stats": {
                    "frames_processed": frame_id,
                    "total_frames": total_frames,
                    "total_detections": total_detections,
                    "processing_time_seconds": round(total_processing_time, 2),
                    "processing_time_ms": round(total_processing_time * 1000, 2),
                    "avg_inference_time": round((total_processing_time / frame_id * 1000), 2) if frame_id > 0 else 0
                },
                "output_info": {
                    "output_path": output_path if save_output else None,
                    "file_size": os.path.getsize(output_path) if (
                                save_output and output_path and os.path.exists(output_path)) else 0
                },
                "detection_results": all_frame_results  # æ‰€æœ‰å¸§çš„æ£€æµ‹ç»“æžœ
            }

            asyncio.run(websocket.send_json(complete_message))

        except Exception as e:
            self.logger.error(f"Error in video processing thread for client {client_id}: {str(e)}")
            asyncio.run(self._send_error(websocket, str(e)))
        finally:
            # æ¸…ç†èµ„æº
            if client_id in self.processing_threads:
                del self.processing_threads[client_id]

    async def process_camera_frame(self, frame_data, client_id: str, frame_id: Optional[int] = None):
        """å¤„ç†æ‘„åƒå¤´å¸§å¹¶è¿”å›žç»“æžœ"""
        try:
            # è§£ç base64å›¾åƒæ•°æ®
            if ',' in frame_data:
                frame_data = frame_data.split(',')[1]  # ç§»é™¤data:image/jpeg;base64,å‰ç¼€

            decoded_data = base64.b64decode(frame_data)
            np_arr = np.frombuffer(decoded_data, np.uint8)
            frame = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

            if frame is None:
                raise ValueError("Failed to decode camera frame")

            # è®°å½•å¸§å¤§å°
            self.logger.info(f"Processing camera frame {frame_id} for client {client_id}, shape: {frame.shape}")

            # è¿è¡Œæ¨¡åž‹æŽ¨ç†
            start_time = time.time()
            results = self.model(frame)[0]
            inference_time = time.time() - start_time

            # èŽ·å–æ£€æµ‹ç»“æžœ
            boxes = results.boxes
            detection_params = []

            if len(boxes) > 0:
                location_list = boxes.xyxy.cpu().numpy().tolist() if hasattr(boxes.xyxy, 'cpu') else boxes.xyxy.tolist()
                cls_list = boxes.cls.cpu().numpy().tolist() if hasattr(boxes.cls, 'cpu') else boxes.cls.tolist()
                conf_list = boxes.conf.cpu().numpy().tolist() if hasattr(boxes.conf, 'cpu') else boxes.conf.tolist()

                for box, cls, conf in zip(location_list, cls_list, conf_list):
                    cls_int = int(cls)
                    class_name = self.config.CH_names[cls_int] if cls_int < len(
                        self.config.CH_names) else f"æœªçŸ¥ç±»åˆ«{cls_int}"
                    detection_params.append({
                        "bbox": [int(x) for x in box],  # x1, y1, x2, y2
                        "class": cls_int,
                        "class_name": class_name,
                        "confidence": float(conf)
                    })

            # èŽ·å–æ ‡æ³¨åŽçš„å›¾åƒ
            annotated_frame = results.plot()

            # å°†å›¾åƒç¼–ç ä¸ºJPEGï¼Œç„¶åŽè½¬æ¢ä¸ºbase64
            _, buffer = cv2.imencode('.jpg', annotated_frame)
            encoded_frame = base64.b64encode(buffer).decode('utf-8')

            # æž„å»ºå¹¶è¿”å›žç»“æžœ
            result = {
                "type": "camera_frame_result",
                "frame_id": frame_id,
                "detections": detection_params,
                "detection_count": len(detection_params),
                "annotated_frame": f"data:image/jpeg;base64,{encoded_frame}",
                "inference_time": round(inference_time * 1000, 2)  # æ¯«ç§’
            }

            # å‘é€ç»“æžœç»™å®¢æˆ·ç«¯
            if client_id in self.active_connections:
                await self.active_connections[client_id].send_json(result)
                return result

        except Exception as e:
            self.logger.error(f"Error processing camera frame {frame_id} for client {client_id}: {str(e)}")
            if client_id in self.active_connections:
                await self.active_connections[client_id].send_json({
                    "type": "error",
                    "frame_id": frame_id,
                    "message": str(e)
                })
            return None

    async def start_camera_stream(self, client_id: str):
        """å¼€å§‹æ‘„åƒå¤´æµå¤„ç†"""
        if client_id not in self.active_connections:
            self.logger.error(f"No active connection for client {client_id}")
            return

        websocket = self.active_connections[client_id]

        # å‘é€ç¡®è®¤æ¶ˆæ¯
        await websocket.send_json({
            "type": "camera_stream_started",
            "client_id": client_id,
            "message": "Camera stream processing started"
        })

    async def stop_camera_stream(self, client_id: str):
        """åœæ­¢æ‘„åƒå¤´æµå¤„ç†"""
        if client_id not in self.active_connections:
            return

        websocket = self.active_connections[client_id]

        # å‘é€åœæ­¢ç¡®è®¤æ¶ˆæ¯
        await websocket.send_json({
            "type": "camera_stream_stopped",
            "client_id": client_id,
            "message": "Camera stream processing stopped"
        })

    async def _send_error(self, websocket, message):
        """å‘é€é”™è¯¯æ¶ˆæ¯ç»™å®¢æˆ·ç«¯"""
        try:
            await websocket.send_json({
                "type": "error",
                "message": message
            })
        except Exception as e:
            self.logger.error(f"Error sending error message: {str(e)}")